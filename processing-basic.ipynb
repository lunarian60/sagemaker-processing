{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc4f7944",
   "metadata": {},
   "source": [
    "# Basic SageMaker Processing Script\n",
    "\n",
    "이 노트북은 다름 블로그에 실린 내용을 바탕으로 만들어졌습니다. [this](https://aws.amazon.com/blogs/aws/amazon-sagemaker-processing-fully-managed-data-processing-and-model-evaluation/) \n",
    "SageMaker 프로세싱을 사용하여 기차, 테스트 및 유효성 검사 데이터 세트를 생성하는 매우 기본적인 예를 보여줍니다. SageMaker Processing 은 이러한 데이터 세트를 생성하는 데 사용되며, 이 데이터셋은 S3에 다시 기록됩니다.\n",
    "\n",
    "먼저 SklearnProcessor 객체를 만들어 사용하고자 하는 scikit-learn 버전과 관리형 인프라 요구 사항을 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b1b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.20.0\", role=role, instance_type=\"ml.m5.xlarge\", instance_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e8b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_data = \"s3://sagemaker-sample-data-{}/processing/census/census-income.csv\".format(region)\n",
    "df = pd.read_csv(input_data, nrows=10)\n",
    "df.to_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b421c68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preprocessing-basic.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing-basic.py\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read data locally\n",
    "input_data_path = os.path.join(\"/opt/ml/processing/input\", \"dataset.csv\")\n",
    "# Preprocess the data set\n",
    "df = pd.read_csv(input_data_path)\n",
    "downsampled = df\n",
    "print(\"shape of data is:\")\n",
    "print(downsampled.shape)\n",
    "# Split data set into training, validation, and test\n",
    "train, test = train_test_split(downsampled, test_size=0.2)\n",
    "train, validation = train_test_split(train, test_size=0.2)\n",
    "# Create local output directories\n",
    "try:\n",
    "    os.makedirs(\"/opt/ml/processing/output/train\")\n",
    "    os.makedirs(\"/opt/ml/processing/output/validation\")\n",
    "    os.makedirs(\"/opt/ml/processing/output/test\")\n",
    "    print(\"Successfully created directories\")\n",
    "except Exception as e:\n",
    "    # if the Processing call already creates these directories (or directory otherwise cannot be created)\n",
    "    print(e)\n",
    "    print(\"Could Not Make Directories\")\n",
    "    pass\n",
    "\n",
    "# Save data locally\n",
    "try:\n",
    "    train.to_csv(\"/opt/ml/processing/output/train/train.csv\")\n",
    "    validation.to_csv(\"/opt/ml/processing/output/validation/validation.csv\")\n",
    "    test.to_csv(\"/opt/ml/processing/output/test/test.csv\")\n",
    "    print(\"Files Successfully Written\")\n",
    "except Exception as e:\n",
    "    print(\"Could Not Write the Files\")\n",
    "    print(e)\n",
    "    pass\n",
    "\n",
    "print(\"Finished running processing job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae3f5116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2021-06-01-11-31-40-831\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-806174985048/sagemaker-scikit-learn-2021-06-01-11-31-40-831/input/input-1/dataset.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-806174985048/sagemaker-scikit-learn-2021-06-01-11-31-40-831/input/code/preprocessing-basic.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'output-1', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-806174985048/sagemaker-scikit-learn-2021-06-01-11-31-40-831/output/output-1', 'LocalPath': '/opt/ml/processing/output/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'output-2', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-806174985048/sagemaker-scikit-learn-2021-06-01-11-31-40-831/output/output-2', 'LocalPath': '/opt/ml/processing/output/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'output-3', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-806174985048/sagemaker-scikit-learn-2021-06-01-11-31-40-831/output/output-3', 'LocalPath': '/opt/ml/processing/output/test', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".........................\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mshape of data is:\u001b[0m\n",
      "\u001b[34m(10, 43)\u001b[0m\n",
      "\u001b[34m[Errno 17] File exists: '/opt/ml/processing/output/train'\u001b[0m\n",
      "\u001b[34mCould Not Make Directories\u001b[0m\n",
      "\u001b[34mFiles Successfully Written\u001b[0m\n",
      "\u001b[34mFinished running processing job\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code=\"preprocessing-basic.py\",\n",
    "    # arguments = ['arg1', 'arg2'],\n",
    "    inputs=[ProcessingInput(source=\"dataset.csv\", destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/output/train\"),\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/output/validation\"),\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/output/test\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1c9c99",
   "metadata": {},
   "source": [
    "### 실습 예제\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
